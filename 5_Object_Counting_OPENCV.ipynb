{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9219e9fc",
   "metadata": {},
   "source": [
    "Moving objects captured by fixed cameras are the focus of several computer vision applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d88785",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_greyscale(image):\n",
    "    #create copy of original_image\n",
    "    grey = np.zeros((image.shape[0],image.shape[1]))\n",
    "    #using BT.601 to convert image to greysclae\n",
    "    #Gray = (Red * 0.299 + Green * 0.587 + Blue * 0.114)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            grey[i][j] = int(image[i][j][0] * 0.299 + image[i][j][1] * 0.587 + image[i][j][2] * 0.114)\n",
    "    \n",
    "    return grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting frames from video data\n",
    "frames = []\n",
    "cap = cv2.VideoCapture('DatasetC.mpg')\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        #cv2.imshow('frame',frame)\n",
    "        frames.append(ICV_greyscale(frame))\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5fa476",
   "metadata": {},
   "source": [
    "a) Write a function that performs pixel-by-pixel frame differencing using, as reference frame, the first frame of an image sequence. Apply a classification threshold and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_pixel_frame_differencing(ref_frame, cur_frame, threshold_val = 0, show_plot=False):\n",
    "    \n",
    "    #empty image to store image difference values\n",
    "    difference  = np.zeros((ref_frame.shape[0],ref_frame.shape[1]))\n",
    "    \n",
    "    #empty image to store image threshold values\n",
    "    threshold  = np.zeros((ref_frame.shape[0],ref_frame.shape[1]))\n",
    "    \n",
    "    for i in range(threshold.shape[0]):\n",
    "        for j in range(threshold.shape[1]):\n",
    "            #calculating difference beween 2 images co-ordiantes\n",
    "            diff = np.abs(ref_frame[i][j] - cur_frame[i][j])\n",
    "            \n",
    "            difference[i][j] = diff\n",
    "            \n",
    "            #comapring diff with treshold values\n",
    "            if diff > threshold_val:\n",
    "                threshold[i][j] = 1\n",
    "            else:\n",
    "                threshold[i][j] = 0\n",
    "    \n",
    "    if show_plot:\n",
    "        plt.imshow(cur_frame,cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(difference,cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(threshold,cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0faf2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#considering first frame as reference frame\n",
    "ref_frame = frames[0]\n",
    "\n",
    "plt.imshow(ref_frame,cmap='gray')\n",
    "plt.title('Ref frame')\n",
    "plt.show()\n",
    "\n",
    "threshold = 50\n",
    "for frame in frames[1:]:\n",
    "    #performing frame differencing\n",
    "    curent_motion = ICV_pixel_frame_differencing(ref_frame, frame, threshold, show_plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78beba0",
   "metadata": {},
   "source": [
    "b) Repeat the exercise using the previous frame as reference frame (use frame It-1 as reference frame for frame It, for each t). Comment the results in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a21521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 50\n",
    "for i in range(1,len(frames)):\n",
    "    #performing frame differencing using previous frame as ref frame \n",
    "    curent_motion = ICV_pixel_frame_differencing(frames[i-1], frames[i], threshold, show_plot = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9501975",
   "metadata": {},
   "source": [
    "c) Write a function that generates a reference frame (background) for the sequence using for example frame differencing and a weighted temporal averaging algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0249018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_generate_ref_frame(frames):\n",
    "    frames = np.array(frames)\n",
    "\n",
    "    #creating empty image to store the generates reference frame values\n",
    "    background_frame = np.zeros((frames[0].shape[0],frames[0].shape[1]))\n",
    "    \n",
    "    for i in range(background_frame.shape[0]):\n",
    "        for j in range(background_frame.shape[1]):\n",
    "            #getting avg of pixel at particualr co-ordinate\n",
    "            sum_pix = 0\n",
    "            for k in range(len(frames)):\n",
    "                sum_pix += frames[k][i][j]  \n",
    "            background_frame[i][j] = sum_pix // len(frames) \n",
    "        \n",
    "    return background_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef605d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "back = ICV_generate_ref_frame(frames)\n",
    "\n",
    "plt.imshow(back,cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de21e74",
   "metadata": {},
   "source": [
    "d) Write a function that counts the number of moving objects in each frame of a sequence. Generate a bar plot that visualizes the number of objects for each frame of the whole sequence. Discuss in the report the implemented solution, including advantages and disadvantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_image_dilation(image, kernel):\n",
    "    \n",
    "    #calulating kernel multiplication factor \n",
    "    kernel_h = kernel.shape[0]\n",
    "    kernel_w = kernel.shape[1]\n",
    "    \n",
    "    #empty image to store dilated image value\n",
    "    dilated_image = np.zeros((image.shape[0],image.shape[1]))\n",
    "    \n",
    "    for i in range(0+(kernel_h//2), image.shape[0]-(kernel_h//2)): #iterating image height\n",
    "        for j in range(0+(kernel_w//2), image.shape[1]-(kernel_w//2)):\n",
    "            \n",
    "            #splitting the area in image to be dilated\n",
    "            dilate_part = image[i-(kernel_h//2):i+(kernel_w//2)+1,j-(kernel_h//2):j+(kernel_w//2)+1]\n",
    "            \n",
    "            \n",
    "            is_dilate = False #flag to check if co-ordinate can be dialted or not\n",
    "            \n",
    "            for k in range(kernel_h):\n",
    "                for m in range(kernel_w):\n",
    "                    if k==m: #if position is middle value then pass\n",
    "                        pass\n",
    "                    else:\n",
    "                        #checking if any neighbour matches with kernel value \n",
    "                        if dilate_part[k][m]==kernel[k][m]:\n",
    "                            is_dilate = True\n",
    "                            break\n",
    "             \n",
    "            #if flag is true then replace co-ordinate with 1 else 0\n",
    "            if is_dilate == True:\n",
    "                dilated_image[i][j]=1\n",
    "            else:\n",
    "                dilated_image[i][j]=0\n",
    "    \n",
    "    return dilated_image\n",
    "                                \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798ac562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_image_eroison(image):\n",
    "    #calulating kernel multiplication factor \n",
    "    kernel_h = kernel.shape[0]\n",
    "    kernel_w = kernel.shape[1]\n",
    "    \n",
    "    #empty image to store eroded image value\n",
    "    eroded_image = np.zeros((image.shape[0],image.shape[1]))\n",
    "    \n",
    "    for i in range(0+(kernel_h//2), image.shape[0]-(kernel_h//2)): #iterating image height\n",
    "        for j in range(0+(kernel_w//2), image.shape[1]-(kernel_w//2)):\n",
    "            erode_part = image[i-(kernel_h//2):i+(kernel_w//2)+1,j-(kernel_h//2):j+(kernel_w//2)+1]\n",
    "            \n",
    "            is_erode = True#flag to check if co-ordinate can be eroded or not\n",
    "            \n",
    "            for k in range(kernel_h):\n",
    "                for m in range(kernel_w):\n",
    "                    if k==m:#if position is middle value then pass\n",
    "                        pass\n",
    "                    else:\n",
    "                        #if any of neighbours doesnt matchs with kernel then co-ordinate cannot be eroded\n",
    "                        if erode_part[k][m]!=kernel[k][m]:\n",
    "                            is_erode = False\n",
    "                            break\n",
    "            #if flag is true then replace co-ordinate with 1 else 0\n",
    "            if is_erode:\n",
    "                eroded_image[i][j]=1\n",
    "            else:\n",
    "                eroded_image[i][j]=0\n",
    "                \n",
    "    return eroded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38cd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_flood_fill(frame_erosion,x,y):\n",
    "    \n",
    "    frame_flooded = frame_erosion\n",
    "    \n",
    "    frontier = {(x,y)}\n",
    "    \n",
    "    while frontier != {}:\n",
    "        next_frontier = set()\n",
    "        for node in frontier:\n",
    "            # check right\n",
    "            if node[1]<frame_erosion.shape[1]-1:\n",
    "                right_node = (node[0],node[1]+1)\n",
    "                if frame_erosion[right_node] == 1:\n",
    "                    next_frontier |= {right_node}\n",
    "            \n",
    "            # check below\n",
    "            if node[0]<frame_erosion.shape[0]-1:\n",
    "                below_node = (node[0]+1, node[1])\n",
    "                if frame_erosion[below_node] == 1:\n",
    "                    next_frontier |= {below_node}\n",
    "            \n",
    "            # check above\n",
    "            if node[0]>0:\n",
    "                above_node = (node[0]-1, node[1])\n",
    "                if frame_erosion[above_node] == 1:\n",
    "                    next_frontier |= {above_node}\n",
    "            \n",
    "            \n",
    "            # check left\n",
    "            if node[1]>0:\n",
    "                left_node = (node[0], node[1]-1)\n",
    "                if frame_erosion[left_node] == 1:\n",
    "                    next_frontier |= {left_node}\n",
    "            \n",
    "            \n",
    "            \n",
    "            for nodes in next_frontier:\n",
    "                frame_flooded[node] = 0.\n",
    "            frontier = next_frontier\n",
    "    \n",
    "    return matrix_flooded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_count_object(frames, threshold=50):\n",
    "    \n",
    "    ref_frame = ICV_generate_ref_frame(frames)\n",
    "    \n",
    "    object_count = []\n",
    "    \n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame_threshold = ICV_pixel_frame_differencing(ref_frame, frame, threshold, show_plot=False)\n",
    "        \n",
    "        #image_dilation\n",
    "        frame_dilate = ICV_image_dilation(frame_threshold, kernel)\n",
    "        \n",
    "        #image erosion\n",
    "        frame_erosion = ICV_image_dilation(frame_dilate, kernel)\n",
    "        \n",
    "        #Count object using flood fill\n",
    "        count = 0\n",
    "        filled_pixels = []\n",
    "        for i in range(frame_erosion.shape[0]):\n",
    "            for j in range(frame_erosion.shape[1]):\n",
    "                if int(frame_erosion[i][j]) == 1 :\n",
    "                    frame_erosion = ICV_flood_fill(frame_erosion,i,j)\n",
    "                    count +=1\n",
    "        object_count.append(count)\n",
    "    \n",
    "    plt.plot(range(len(frames)),object_count)\n",
    "    plt.xlabel('Frames')\n",
    "    plt.ylabel('Object count')\n",
    "    plt.show()\n",
    "                    \n",
    "        \n",
    "        \n",
    "threshold=150\n",
    "ICV_count_object(frames,threshold)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd795d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
