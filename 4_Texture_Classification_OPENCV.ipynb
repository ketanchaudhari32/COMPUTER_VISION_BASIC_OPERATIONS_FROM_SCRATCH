{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1944486",
   "metadata": {},
   "source": [
    "The Local Binary Pattern (LBP) operator describes the surroundings of a pixel by generating a bit-code from the binary derivatives of a pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175431e",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc4372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_greyscale_histogram(image):\n",
    "    bins = np.arange(0,256) #creating empty array of pixel values from 0-255\n",
    "    bins = bins.reshape(256,1).ravel()\n",
    "    \n",
    "    #creating emppty array to store pixel count values\n",
    "    grey_hist = np.zeros((bins.shape[0]))\n",
    "\n",
    "    for i in range(bins.shape[0]): #iterating over bins indexes i.e 0,1,.......,255\n",
    "        #getting sum of booelan values which pixel value matches the index of bins\n",
    "        grey_hist[i] = np.sum(image[:,:]==i)\n",
    "    \n",
    "    return grey_hist.ravel(),bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_greyscale(image):\n",
    "    #create copy of original_image\n",
    "    grey = np.zeros((image.shape[0],image.shape[1]))\n",
    "    #using BT.601 to convert image to greysclae\n",
    "    #Gray = (Red * 0.299 + Green * 0.587 + Blue * 0.114)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            grey[i][j] = image[i][j][0] * 0.299 + image[i][j][1] * 0.587 + image[i][j][2] * 0.114\n",
    "    \n",
    "    return grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ba6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_histogram_intersection(hist1, hist2):\n",
    "    #variables to store intersection sum\n",
    "    intersect = 0\n",
    "    \n",
    "    for i in range(len(hist1)):\n",
    "        #calculation sum of min intercestion \n",
    "        intersect += min(float(hist1[i]),float(hist2[i]))\n",
    "        \n",
    "    return intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be07119",
   "metadata": {},
   "source": [
    "a) Write a function that divides a greyscale image into equally sized non-overlapping windows and returns the feature descriptor for each window as distribution of LBP codes. For each pixel in the window, compare the pixel to each of its 8 neighbours. Convert the resulting bit-codes (base 2) to decimals (base 10 numbers) and compute their histogram over the window. Normalize the histogram (which is now a feature descriptor representing the window). Show in the report the resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function for comparing values of neighbours \n",
    "def ICV_feature_compare(x,y):\n",
    "    if x>y:\n",
    "        #neighbour value is greater than middel value then return 1\n",
    "        return 1\n",
    "    else:\n",
    "        #if less than return 0\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dbe883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_feature_descriptor(image, block_size, show_hist = False):\n",
    "    #dividing image in equal size blocks\n",
    "    windows = [] #array to store each block\n",
    "    for i in range(0,image.shape[0],block_size):\n",
    "        for j in range(0,image.shape[1],block_size): \n",
    "            windows.append(image[i:i+block_size, j:j+block_size])#dividing image in equal size windows\n",
    "    #print(windows)\n",
    "\n",
    "    #arrays to store feature descriptor of each window\n",
    "    feature_windows = []\n",
    "    feature_window_normalize = []\n",
    "    \n",
    "    for count, window in enumerate(windows):#iterating over each window \n",
    "        padded_window = np.zeros((window.shape[0]+2,window.shape[1]+2)) #adding a padding layer to window\n",
    "        padded_window[1:-1,1:-1] = window[:,:]\n",
    "        \n",
    "        feature_window = window.copy()\n",
    "        for i in range(0,feature_window.shape[0]):\n",
    "            for j in range(0,feature_window.shape[1]):\n",
    "                #calulate neighour\n",
    "                n8,n7,n6,n5,n4,n3,n2,n1 = padded_window[i-1,j-1],padded_window[i-1,j],padded_window[i-1,j+1],padded_window[i,j+1],padded_window[i+1,j+1],padded_window[i+1,j],padded_window[i+1,j-1],padded_window[i,j-1]\n",
    "                n8 = ICV_feature_compare(n1,feature_window[i][j]) #NorthWest\n",
    "                n7 = ICV_feature_compare(n2,feature_window[i][j]) #North\n",
    "                n6 = ICV_feature_compare(n3,feature_window[i][j]) #NorthEast\n",
    "                n5 = ICV_feature_compare(n4,feature_window[i][j]) #East\n",
    "                n4 = ICV_feature_compare(n5,feature_window[i][j]) #South East\n",
    "                n3 = ICV_feature_compare(n6,feature_window[i][j]) #South\n",
    "                n2 = ICV_feature_compare(n7,feature_window[i][j]) #South West\n",
    "                n1 = ICV_feature_compare(n8,feature_window[i][j]) #West\n",
    "                \n",
    "                #LBP calculation for middle value\n",
    "                feature_window[i][j] = (2**0) * n1 + (2**1) * n2 + (2**2) * n3 + (2**3) * n4 + (2**4) * n5 + (2**5) * n6 + (2**6) * n7 + (2**7) * n8\n",
    "        \n",
    "        feature_windows.append(feature_window)\n",
    "        \n",
    "        \n",
    "        #calulating histogram of each window\n",
    "        hist, bins = ICV_greyscale_histogram(feature_window)\n",
    "        hist = np.array(hist)\n",
    "        norm_hist = hist.copy()\n",
    "        norm_hist[:] = (hist[:] - np.min(hist)) / (np.max(hist) - np.min(hist)) #normalize histogram\n",
    "        \n",
    "        feature_window_normalize.append(norm_hist)\n",
    "        \n",
    "        #ploting image and LBP\n",
    "        if (count == 3 or count == 4 or count == 5)  and show_hist==True:\n",
    "            plt.axis('off')\n",
    "            plt.imshow(window,cmap='gray')\n",
    "            plt.title(f'Original Window no:{count}')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.axis('off')\n",
    "            plt.imshow(feature_window,cmap='gray')\n",
    "            plt.title(f'LBP of Window no:{count}')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            plt.plot(bins, hist.ravel())\n",
    "            plt.title(f'Histogram of LBP no:{count}')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            plt.plot(bins, norm_hist.ravel())\n",
    "            plt.title(f'Normalized Histogram of LBP no:{count}')\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return feature_windows, np.array(feature_window_normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81acc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('./DatasetA/face-1.jpg')\n",
    "image = ICV_greyscale(image)\n",
    "image = ICV_feature_descriptor(image, 40, show_hist = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade8bbd",
   "metadata": {},
   "source": [
    "b) Come up with a descriptor that represents the whole image as consisting of multiple windows. For example, you could combine several local descriptions into a global description by concatenation. Discuss in the report alternative approaches. Using the global descriptor you created, implement a classification process that separates the images in the dataset into two categories: face images and non-face images (for example, you could use histogram similarities). Comment the results in the report. Is the global descriptor able to represent whole images of different types (e.g. faces vs. cars)? Identify problems (if any), discuss them in the report and suggest possible solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_global_descriptor(image, block_size, show_img=False, show_hist=False):\n",
    "    \n",
    "    #getting local descriptors of image\n",
    "    image_local_descriptor, normalized_histogram = ICV_feature_descriptor(image, block_size)\n",
    "    \n",
    "    img = image.copy()\n",
    "    count = 0\n",
    "    for i in range(0,img.shape[0],block_size):\n",
    "        for j in range(0,img.shape[1],block_size): \n",
    "            #connecting local descriptor to create global descriptor \n",
    "            img[i:i+block_size, j:j+block_size] =  image_local_descriptor[count]\n",
    "            count+=1\n",
    "    if show_img:\n",
    "        plt.imshow(img, cmap ='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    return img, normalized_histogram\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = cv2.imread('./DatasetA/face-1.jpg')\n",
    "face = ICV_greyscale(face)\n",
    "face = ICV_global_descriptor(face, 40,show_img=True)\n",
    "\n",
    "car = cv2.imread('./DatasetA/car-1.jpg')\n",
    "car = ICV_greyscale(car)\n",
    "car = ICV_global_descriptor(car, 40,show_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a764646",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 40\n",
    "\n",
    "#Traing on face data to get threshold value for classification\n",
    "train_face_A = cv2.imread('./DatasetA/face-1.jpg')\n",
    "train_face_A = ICV_greyscale(train_face_A)\n",
    "train_face_lsb_A,train_face_norm_hist_A = ICV_global_descriptor(train_face_A, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "train_face_B = cv2.imread('./DatasetA/face-2.jpg')\n",
    "train_face_B = ICV_greyscale(train_face_B)\n",
    "train_face_lsb_B,train_face_norm_hist_B = ICV_global_descriptor(train_face_B, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "train_face_C = cv2.imread('./DatasetA/face-3.jpg')\n",
    "train_face_C = ICV_greyscale(train_face_C)\n",
    "train_face_lsb_C,train_face_norm_hist_C = ICV_global_descriptor(train_face_C, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "\n",
    "#Calculating mean of threshold value \n",
    "threshold_A_B = ICV_histogram_intersection(train_face_norm_hist_A.ravel(), train_face_norm_hist_B.ravel())\n",
    "threshold_B_C = ICV_histogram_intersection(train_face_norm_hist_B.ravel(), train_face_norm_hist_C.ravel())\n",
    "threshold_A_C = ICV_histogram_intersection(train_face_norm_hist_A.ravel(), train_face_norm_hist_C.ravel())\n",
    "\n",
    "classify_threshold = np.mean([threshold_A_B,threshold_A_C,threshold_B_C])\n",
    "\n",
    "\n",
    "images_path = os.getcwd()+'/DatasetA' #input image path\n",
    "for images in os.listdir(images_path): #parsing through all files in directory\n",
    "    if images[-3:]=='jpg': #checking if file is image or not\n",
    "        images_name = images_path + '/' + images #getting image name\n",
    "        img = cv2.imread(images_name) #reading image\n",
    "        \n",
    "        img = ICV_greyscale(cv2.imread(images_name))\n",
    "        \n",
    "        #finding global descriptor of each image\n",
    "        img_lsb, img_norm_hist = ICV_global_descriptor(img, block_size,show_img=False, show_hist = False)\n",
    "        \n",
    "        img_threshold = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_B.ravel())\n",
    "        \n",
    "        #testing classification \n",
    "        threshold_img_A = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_A.ravel())\n",
    "        threshold_img_B = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_B.ravel())\n",
    "        threshold_img_C = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_C.ravel())\n",
    "\n",
    "        img_threshold = np.mean([threshold_img_A,threshold_img_B,threshold_img_C])\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.title(images + ' original')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img_lsb,cmap='gray')\n",
    "        plt.title(images + ' LBP')\n",
    "        plt.show()\n",
    "        \n",
    "        if img_threshold <= (classify_threshold):\n",
    "            print('Image contains face')\n",
    "        else:\n",
    "            print('Image contain non-face objects')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f2a01",
   "metadata": {},
   "source": [
    "c) Decrease the window size and perform classification again. Comment the results in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 10\n",
    "\n",
    "#Traing on face data to get threshold value for classification\n",
    "train_face_A = cv2.imread('./DatasetA/face-1.jpg')\n",
    "train_face_A = ICV_greyscale(train_face_A)\n",
    "train_face_lsb_A,train_face_norm_hist_A = ICV_global_descriptor(train_face_A, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "train_face_B = cv2.imread('./DatasetA/face-2.jpg')\n",
    "train_face_B = ICV_greyscale(train_face_B)\n",
    "train_face_lsb_B,train_face_norm_hist_B = ICV_global_descriptor(train_face_B, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "train_face_C = cv2.imread('./DatasetA/face-3.jpg')\n",
    "train_face_C = ICV_greyscale(train_face_C)\n",
    "train_face_lsb_C,train_face_norm_hist_C = ICV_global_descriptor(train_face_C, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "\n",
    "#Calculating mean of threshold value \n",
    "threshold_A_B = ICV_histogram_intersection(train_face_norm_hist_A.ravel(), train_face_norm_hist_B.ravel())\n",
    "threshold_B_C = ICV_histogram_intersection(train_face_norm_hist_B.ravel(), train_face_norm_hist_C.ravel())\n",
    "threshold_A_C = ICV_histogram_intersection(train_face_norm_hist_A.ravel(), train_face_norm_hist_C.ravel())\n",
    "\n",
    "classify_threshold = np.mean([threshold_A_B,threshold_A_C,threshold_B_C])\n",
    "\n",
    "\n",
    "\n",
    "images_path = os.getcwd()+'/DatasetA' #input image path\n",
    "for images in os.listdir(images_path): #parsing through all files in directory\n",
    "    if images[-3:]=='jpg': #checking if file is image or not\n",
    "        images_name = images_path + '/' + images #getting image name\n",
    "        img = cv2.imread(images_name) #reading image\n",
    "        \n",
    "        img = ICV_greyscale(cv2.imread(images_name))\n",
    "        \n",
    "        #finding global descriptor of each image\n",
    "        img_lsb, img_norm_hist = ICV_global_descriptor(img, block_size,show_img=False, show_hist = False)\n",
    "        \n",
    "        img_threshold = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_B.ravel())\n",
    "        \n",
    "        #testing classification \n",
    "        threshold_img_A = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_A.ravel())\n",
    "        threshold_img_B = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_B.ravel())\n",
    "        threshold_img_C = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_C.ravel())\n",
    "\n",
    "        img_threshold = np.mean([threshold_img_A,threshold_img_B,threshold_img_C])\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.title(images + ' original')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img_lsb,cmap='gray')\n",
    "        plt.title(images + ' LBP')\n",
    "        plt.show()\n",
    "        \n",
    "        if img_threshold <= (classify_threshold):\n",
    "            print('Image contains face')\n",
    "        else:\n",
    "            print('Image contain non-face objects')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37895be8",
   "metadata": {},
   "source": [
    "d) Increase the window size and perform classification again. Comment the results in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06358806",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 70\n",
    "\n",
    "#Traing on face data to get threshold value for classification\n",
    "train_face_A = cv2.imread('./DatasetA/face-1.jpg')\n",
    "train_face_A = ICV_greyscale(train_face_A)\n",
    "train_face_lsb_A,train_face_norm_hist_A = ICV_global_descriptor(train_face_A, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "train_face_B = cv2.imread('./DatasetA/face-2.jpg')\n",
    "train_face_B = ICV_greyscale(train_face_B)\n",
    "train_face_lsb_B,train_face_norm_hist_B = ICV_global_descriptor(train_face_B, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "train_face_C = cv2.imread('./DatasetA/face-3.jpg')\n",
    "train_face_C = ICV_greyscale(train_face_C)\n",
    "train_face_lsb_C,train_face_norm_hist_C = ICV_global_descriptor(train_face_C, block_size,show_img=False, show_hist = False)\n",
    "\n",
    "\n",
    "#Calculating mean of threshold value \n",
    "threshold_A_B = ICV_histogram_intersection(train_face_norm_hist_A.ravel(), train_face_norm_hist_B.ravel())\n",
    "threshold_B_C = ICV_histogram_intersection(train_face_norm_hist_B.ravel(), train_face_norm_hist_C.ravel())\n",
    "threshold_A_C = ICV_histogram_intersection(train_face_norm_hist_A.ravel(), train_face_norm_hist_C.ravel())\n",
    "\n",
    "classify_threshold = np.mean([threshold_A_B,threshold_A_C,threshold_B_C])\n",
    "\n",
    "\n",
    "images_path = os.getcwd()+'/DatasetA' #input image path\n",
    "for images in os.listdir(images_path): #parsing through all files in directory\n",
    "    if images[-3:]=='jpg': #checking if file is image or not\n",
    "        images_name = images_path + '/' + images #getting image name\n",
    "        img = cv2.imread(images_name) #reading image\n",
    "        \n",
    "        img = ICV_greyscale(cv2.imread(images_name))\n",
    "        \n",
    "        #finding global descriptor of each image\n",
    "        img_lsb, img_norm_hist = ICV_global_descriptor(img, block_size,show_img=False, show_hist = False)\n",
    "        \n",
    "        img_threshold = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_B.ravel())\n",
    "        \n",
    "        #testing classification \n",
    "        threshold_img_A = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_A.ravel())\n",
    "        threshold_img_B = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_B.ravel())\n",
    "        threshold_img_C = ICV_histogram_intersection(img_norm_hist.ravel(), train_face_norm_hist_C.ravel())\n",
    "\n",
    "        img_threshold = np.mean([threshold_img_A,threshold_img_B,threshold_img_C])\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img,cmap='gray')\n",
    "        plt.title(images + ' original')\n",
    "        plt.show()\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(img_lsb,cmap='gray')\n",
    "        plt.title(images + ' LBP')\n",
    "        plt.show()\n",
    "        \n",
    "        if img_threshold <= (classify_threshold):\n",
    "            print('Image contains face')\n",
    "        else:\n",
    "            print('Image contain non-face objects')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c58c4a",
   "metadata": {},
   "source": [
    "e) Discuss how LBP can be used or modified for the analysis of dynamic textures in a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be00ee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
